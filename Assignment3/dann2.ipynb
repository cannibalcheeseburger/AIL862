{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision.models import mobilenet_v2\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 50\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_classes = 3  # Adjust based on your dataset\n",
    "\n",
    "# Custom Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = os.listdir(root_dir)\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        for cls in self.classes:\n",
    "            class_dir = os.path.join(root_dir, cls)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                self.images.append(os.path.join(class_dir, img_name))\n",
    "                self.labels.append(self.class_to_idx[cls])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Load the pre-trained feature extractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnlabelledDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Path to the unlabelled dataset directory\n",
    "\n",
    "# Define transformations for the unlabelled dataset\n",
    "transform_unlabelled = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "source_dataset = CustomDataset(root_dir='data/synthetic/cifar10', transform=transform)\n",
    "target_dataset = UnlabelledDataset(root_dir='data/real/unlabelled', transform=transform_unlabelled)\n",
    "\n",
    "\n",
    "source_loader = DataLoader(source_dataset, batch_size=batch_size, shuffle=True)\n",
    "target_loader = DataLoader(target_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kashp\\miniconda3\\envs\\cva3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kashp\\miniconda3\\envs\\cva3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashp\\AppData\\Local\\Temp\\ipykernel_11680\\3620803909.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        # Load pre-trained MobileNetV2\n",
    "        mobilenet = mobilenet_v2(pretrained=True)\n",
    "        \n",
    "        # Freeze all parameters\n",
    "        for param in mobilenet.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Use all layers except the last classifier\n",
    "        self.features = mobilenet.features\n",
    "        \n",
    "        # Add a simple classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1280, num_classes)  # MobileNetV2's last conv layer has 1280 channels\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "def load_model(model, path, device):\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    print(f\"Model loaded from {path}\")\n",
    "    return model\n",
    "\n",
    "# Load the saved model\n",
    "feature_extractor = FeatureExtractor(num_classes=3).to(device)\n",
    "feature_extractor = load_model(feature_extractor, 'model.pth', device)\n",
    "feature_extractor.classifier = nn.Identity()  # Remove the classifier part\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DANN(nn.Module):\n",
    "    def __init__(self, feature_extractor, num_classes):\n",
    "        super(DANN, self).__init__()\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.class_classifier = nn.Linear(1280, num_classes)\n",
    "        self.domain_classifier = nn.Sequential(\n",
    "            nn.Linear(1280, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, alpha):\n",
    "        features = self.feature_extractor(x)\n",
    "        class_output = self.class_classifier(features)\n",
    "        reverse_features = GradientReversalLayer.apply(features, alpha)\n",
    "        domain_output = self.domain_classifier(reverse_features)\n",
    "        return class_output, domain_output\n",
    "\n",
    "\n",
    "class GradientReversalLayer(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "        return output, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ood_filter(model, data_loader, threshold=0.8):\n",
    "    model.eval()\n",
    "    filtered_data = []\n",
    "    filtered_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs, _ = model(inputs, alpha=0)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            max_probs, predicted_labels = torch.max(probabilities, dim=1)\n",
    "            for i, prob in enumerate(max_probs):\n",
    "                if prob > threshold:\n",
    "                    filtered_data.append(inputs[i].cpu())\n",
    "                    filtered_labels.append(predicted_labels[i].item())\n",
    "    return filtered_data, filtered_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dann(model, source_loader, target_loader, optimizer, num_epochs):\n",
    "    global source_dataset  # Declare source_dataset as global\n",
    "    for epoch in range(num_epochs):      \n",
    "        model.train()\n",
    "        for (source_data, source_labels), target_data in zip(source_loader, target_loader):\n",
    "            source_data, source_labels = source_data.to(device), source_labels.to(device)\n",
    "            target_data = target_data.to(device)  # Now target_data is already a tensor\n",
    "\n",
    "            # Create domain labels\n",
    "            source_domain = torch.zeros(source_data.size(0)).long().to(device)\n",
    "            target_domain = torch.ones(target_data.size(0)).long().to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            alpha = 2 / (1 + np.exp(-10 * epoch / num_epochs)) - 1\n",
    "            source_class_output, source_domain_output = model(source_data, alpha)\n",
    "            _, target_domain_output = model(target_data, alpha)\n",
    "\n",
    "            # Compute losses\n",
    "            class_loss = nn.CrossEntropyLoss()(source_class_output, source_labels)\n",
    "            domain_loss = nn.CrossEntropyLoss()(source_domain_output, source_domain) + \\\n",
    "                          nn.CrossEntropyLoss()(target_domain_output, target_domain)\n",
    "            \n",
    "            loss = class_loss + 0.1 * domain_loss\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Class Loss: {class_loss.item():.4f}, Domain Loss: {domain_loss.item():.4f}')\n",
    "\n",
    "        # OOD Filtering and Pseudolabeling (every 5 epochs)\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            filtered_data, filtered_labels = ood_filter(model, target_loader)\n",
    "            print(f'Filtered samples: {len(filtered_data)}')\n",
    "            \n",
    "            # Add filtered data to source dataset (pseudolabeling)\n",
    "            for data, label in zip(filtered_data, filtered_labels):\n",
    "                img = transforms.ToPILImage()(data)\n",
    "                source_dataset.images.append(img)\n",
    "                source_dataset.labels.append(label)\n",
    "            \n",
    "            # Recreate source dataloader with updated dataset\n",
    "            source_loader = DataLoader(source_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.6060, Class Loss: 0.4661, Domain Loss: 1.3997\n"
     ]
    }
   ],
   "source": [
    "# Evaluation function\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs, _ = model(inputs, alpha=0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    return accuracy_score(all_labels, all_preds)\n",
    "\n",
    "# Initialize model, optimizer\n",
    "model = DANN(feature_extractor, num_classes).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_dann(model, source_loader, target_loader, optimizer, num_epochs)\n",
    "\n",
    "# Evaluate the model\n",
    "source_accuracy = evaluate(model, source_loader)\n",
    "target_accuracy = evaluate(model, target_loader)\n",
    "\n",
    "print(f'Source Accuracy: {source_accuracy:.4f}')\n",
    "print(f'Target Accuracy: {target_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cva3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
